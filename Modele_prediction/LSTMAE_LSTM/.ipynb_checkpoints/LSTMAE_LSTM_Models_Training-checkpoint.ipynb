{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xj51I-SWOQ_C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "###################   PREPROCESSING SECTION  ##########################\n",
    "\n",
    "categories = [\n",
    "    \"shoulder_abduction_\",\n",
    "    \"shoulder_adduction_\",\n",
    "    \"shoulder_flexion_\",\n",
    "    \"shoulder_extension_\",\n",
    "    \"elbow_extension_\",\n",
    "    \"elbow_flexion_\",\n",
    "    \"rest_low_arm_\",\n",
    "    \"rest_post_elbow_flexion_\",\n",
    "    \"rest_post_shoulder_flexion_\",\n",
    "    \"rest_post_abduction_\"\n",
    "]\n",
    "\n",
    "#Create 3d array for lstmae training\n",
    "def create_time_series(filepath, n_timesteps):\n",
    "    time_series = []\n",
    "    Y = []\n",
    "    first_y = True \n",
    "    first_windows = True\n",
    "    for category in categories:\n",
    "        print(category)\n",
    "        data = np.load(filepath + \"/\" + category + \"3s_2000Hz.npy\")\n",
    "        data = normalize(data, axis=1)\n",
    "        windows = split_into_windows(data, n_timesteps)\n",
    "        y_category = label_category(category, len(windows))\n",
    "        if first_y:                                        \n",
    "            Y = np.array(y_category)\n",
    "            first_y = False\n",
    "        else:\n",
    "            Y = np.vstack((Y,y_category))\n",
    "\n",
    "        if first_windows:                                   \n",
    "            time_series = windows\n",
    "            first_windows = False\n",
    "        else:\n",
    "            time_series = np.vstack((time_series, windows))\n",
    "\n",
    "    return time_series, Y\n",
    "\n",
    "\n",
    "# Create windows of n_timesteps BY ADDING PADDING AND THEN SPLITTING THE ARRAY\n",
    "def split_into_windows(X, n_timesteps):\n",
    "    windows = []\n",
    "\n",
    "    # Fill array until it can be split into windows of n timesteps (elements)\n",
    "    while len(X) % n_timesteps != 0:\n",
    "        X = np.row_stack((X, X[ len(X) -1 ]))\n",
    "\n",
    "    windows = np.array_split(X, (len(X) / n_timesteps), axis=0)\n",
    "    return np.array(windows)\n",
    "\n",
    "\n",
    "# Create sliding windows of n_timesteps (data augmentation technique)\n",
    "def create_sliding_windows(data, n_timesteps):\n",
    "    windows = []\n",
    "    for i in range(data.shape[0] - n_timesteps):\n",
    "      windows.append(data[i: i + n_timesteps])\n",
    "\n",
    "    return np.array(windows)\n",
    "\n",
    "#Label one category\n",
    "def label_category(category, windows_length):\n",
    "    indexLabel = categories.index(category)\n",
    "    Y = np.full((windows_length, 1), indexLabel)\n",
    "    return Y\n",
    "\n",
    "#Visualize reconstruction of input data to evaluate the performance of the autoencoder\n",
    "def visualize_reconstruction(X, model):\n",
    "    X_predict = encoder_decoder.predict(X)\n",
    "      \n",
    "    fig, axs = plt.subplots(2)\n",
    "    fig.suptitle('Reconstruction')\n",
    "    for i in range(100, 150): # Choose intervals\n",
    "      axs[0].plot(X[i])\n",
    "      axs[1].plot(X_predict[i])\n",
    "\n",
    "################### LSTMAE TRAINING SECTION  ##########################\n",
    "\n",
    "\n",
    "# Extract features\n",
    "def extract_features(filepath):\n",
    "    n_timesteps = 30 #CHANGE TIMESTEPS HERE\n",
    "    X, Y = create_time_series(filepath, n_timesteps)\n",
    "    print(\"X.shape\", X.shape)\n",
    "    print(\"Y.shape\", Y.shape)\n",
    "    X_encoded, model = evaluate_AE_model(X) #Evaluate model and extract features\n",
    "    visualize_reconstruction(X, model)\n",
    "    print(\"X_encoded.shape\", X_encoded.shape)\n",
    "\n",
    "    Y_categorical = to_categorical(Y) \n",
    "    return X_encoded, Y_categorical\n",
    "\n",
    "\n",
    "# Create, train and evaluate LSTMAE model\n",
    "def evaluate_AE_model(X):\n",
    "\n",
    "    print(\"TRAINING LSTM AUTOENCODER\")\n",
    "    \n",
    "    n_timesteps = X.shape[1] \n",
    "    n_features = X.shape[2]\n",
    "   \n",
    "    # Architecture utilisée lors de l'essai 5 (87% accuracy de classification)\n",
    "\n",
    "    #create encoder part\n",
    "    encoder_decoder = Sequential()\n",
    "    encoder_decoder.add(LSTM(128, activation='relu', input_shape=(n_timesteps, n_features), return_sequences=True))\n",
    "    encoder_decoder.add(LSTM(64, activation='relu', input_shape=(n_timesteps, n_features), return_sequences=True))\n",
    "    encoder_decoder.add(LSTM(32, activation='relu', input_shape=(n_timesteps, n_features), return_sequences=False))\n",
    "\n",
    "    #create decoder part\n",
    "    encoder_decoder.add(RepeatVector(n_timesteps))\n",
    "    encoder_decoder.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "    encoder_decoder.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "    encoder_decoder.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "    encoder_decoder.add(TimeDistributed(Dense(n_features)))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Compile the model\n",
    "    n_epochs = 10\n",
    "    encoder_decoder.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    # Fit data to model\n",
    "    encoder_decoder.fit(X, X, epochs=n_epochs,verbose=1, batch_size=100)\n",
    "\n",
    "    #Save the model\n",
    "    encoder_decoder.save(\"PATH TO OUTPUT DIR\")\n",
    "\n",
    "    #Extract features\n",
    "    encoder = Model(inputs=encoder_decoder.inputs, outputs=encoder_decoder.layers[1].output)\n",
    "    X_encoded = encoder.predict(X)\n",
    "\n",
    "    return X_encoded, encoder_decoder\n",
    "\n",
    "################### LSTM CLASSIFIER TRAINING SECTION  ##########################\n",
    "\n",
    "\n",
    "# fit and evaluate LSTM\n",
    "def evaluate_model(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    print(\"TRAINING CLASSIFIER\")\n",
    "  \n",
    "    n_timesteps = X_train.shape[1]\n",
    "    n_features = X_train.shape[2]\n",
    "    n_outputs = y_train.shape[1]\n",
    "\n",
    "    # Architecture utilisée lors de l'essai 5 (87% accuracy)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True,input_shape=(n_timesteps, n_features)))\n",
    "    model.add(LSTM(75, return_sequences=True,input_shape=( n_timesteps, n_features)))\n",
    "    model.add(LSTM(128, input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(n_outputs, activation=\"softmax\"))\n",
    "\n",
    "    # Compile the model\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    n_epochs = 150\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # Fit data to model\n",
    "    model.fit(X_train, y_train, epochs=n_epochs, batch_size=50)\n",
    "    _, accuracy = model.evaluate(X_test, y_test,verbose=1)\n",
    "    print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "\n",
    "    #Save the model\n",
    "    model.save(\"PATH TO OUTPUT DIR\")\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred,axis = 1) \n",
    "    y_test = np.argmax(y_test,axis = 1)\n",
    "    print(confusion_matrix(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "  \n",
    "###################   MAIN SECTION  ##########################\n",
    "\n",
    "\n",
    "# main function\n",
    "def run_experiment():\n",
    "\n",
    "    file_name = \"PATH TO DATA\"\n",
    "    X_data, Y_data = extract_features(file_name)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_data, Y_data, stratify=Y_data,test_size=0.30, random_state=42\n",
    "    )\n",
    "    evaluate_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "run_experiment()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DonneesMetisModelTraining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
